# -*- coding: utf-8 -*-
"""da_projeto_pandas_mongo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12_bSX-Jh70ny1y6QxvcUZI1NP6P2da11

#Analistas do Projeto:
- Jonathas Carneiro da Silva;  

# Diretrizes do Projeto  
### Nivel Infra   
- O Dataset deve ser salvo em ambiente cloud(Cloud Storage)   
- O arquivo original e tratado deve ser salvo em MongoDB Atlas em coleções diferentes   
- O Dataset devem ser obrigatoriamente salvos em uma bucket do CloudStorage (Original e Tratado)   
### Nivel Pandas   
- O arquivo está em outra linguagem e deve ter seus dados traduzidos para Português-BR   
- Realizar a extração corretamente para um dataframe   
- Verificar a existência de dados inconsistentes e realizar a limpeza para NaN ou NA explicando o porque da decisão   
- Realizar o drop(se necessário) de colunas do dataframe realizando o comentário do porque da exclusão    
- Todos os passos devem ser comentados   
- realizar no mínimo 3 análises apenas numérica   
- realizar plotagens para no mínimo 4 análises   
- chegar a uma conclusão ou sugestão    

###Observação :   
> O que será analisado são os tópicos cumpridos , na ocasião de findar o tempo e algum(ns) não forem contemplados , realize a entrega do que foi concluído.    
> Pedimos que nos conceda acesso ao email professores.bcw4@soulcodeacademy.org para seu projeto no google cloud , adicione um usuário : soulcode  no mongo atlas e compartilhe junto a key de autenticação para acessarmos seu mongo atlas e seja enviado juntamente com o código realizado

# Estrutura do Projeto:  
Para que você se guie adequadamente segue abaixo o significado de cada tópico que aparecerá no índice do projeto:
- Infra : contém todos os imports, install e recebimento e envio dos dados
- Pandas: contém todo processo de tratamento, verificação e análise de dados
  - Constatação : Contém conclusão baseada nos dados ou verificações apresentadas;
  - Inconsistências/ Possíveis Inconsistências: Contém inconsistências que, se for possível, serão tratadas adiante.
  - conclusão : Contém explicação a cerca do não tratamento de alguma inconsistência, não tradução de termos, entre outros, e as razões dessas decisões
  - ? Questionamento : Contém perguntas que surgiram ao decorrer do tratamento ou verificação que se respondidas podém trazer insights interessantes;   
  - A fazer: Contém tarefas que precisam ser concluídas em etapas adiante.
- Conclusão Final/Sugestões: Retorna os insights obtidos durante a análise dos dados e com base neles fornece uma conclusão e/ou sugestão.

# Infra

### Imports e Installs
"""

import pandera as pa
import os
import numpy as np
import pandas as pd
from pymongo import MongoClient
import pymongo
from google.cloud import storage
pip install gcsfs


pip install pymongo


pip install pandera


"""### Conector Cloud Storage Bucket p/ Recebimento de Dados"""

# Configurações Google Cloud Storage
serviceAccount = '/content/total-bliss-377820-f1ed919eefd3.json'
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = serviceAccount

# Configurações Google Cloud Storage
client = storage.Client()
bucket = client.get_bucket('jonathascarneiro01')
bucket.blob('marketing_campaign.csv (1).csv')
path = 'gs://jonathascarneiro01/brutos/marketing_campaign.csv - marketing_campaign.csv (1).csv'

"""### Conector MongoDC Atlas"""

uri = "mongodb+srv://clustersahtc.6wkzjbh.mongodb.net/?authSource=%24external&authMechanism=MONGODB-X509&retryWrites=true&w=majority"
client = MongoClient(
    uri, tls=True, tlsCertificateKeyFile='/content/X509-cert-6861815464451533849.pem')

"""# Pandas

### Read
"""

# Read passando a coluna dt_costumer para tipo date time e colocando config para o dia vir na frente da data
df = pd.read_csv(path, parse_dates=['Dt_Customer'], dayfirst=True)

df

"""# Infra

## Load Dataframe Bruto p/ Bucket Google Cloud
"""

df.to_csv('projeto_pandasmongo_bruto.csv', index=False)

# Carregar direto no bucket
df.to_csv(
    'gs://sahtcarneirodaprojects/brutos/projeto_pandasmongo_bruto.csv', index=False)

"""## Load Dataframe Bruto p/ Database MongoDB Atlas"""

db = client['projetopandasmongo']
colecaobrutos = db['brutos']
colecaobrutos

dfbruto_dict = df.to_dict("records")

colecaobrutos.insert_many(dfbruto_dict)

df.shape

colecaobrutos.count_documents({})

"""# Pandas

## Verificação Inicial

### Datatime  
verificando tipos para saber se a colunas de data de cadastro já constava como datatime, como isso não ocorria, no read adicionei o parse_data para mudar o tipo e a config para colocar o dia na frente da data
"""

df.dtypes

df.info()

"""### Tamanho do Dataframe   
Aqui constatei mais colunas do que é possível visualizar no dataframe, por isso vou mudar a quantidade de colunas máximas a serem visualizadas, para poder fazar a tradução das mesmas mais facilmente.   
Também alterei a quantidade máxima das linhas para na verificação dos dados facilitar a visualização

"""

df.shape

pd.set_option('display.max_columns', None)
pd.set_option('display.max_rows', None)

df

"""## Backup"""

df_backup = df.copy()

"""## Tratamento Inicial

### Tradução
"""

df

"""#### Traduzindo Colunas

Legenda:  
Year_Birth : Ano_Nasc  
Education : Escolaridade  
Marital_Status : Estado_Civil  
Income : Renda  
Kidhome : Qtd_Crianca     
Teenhome : Qtd_Adolescentes  
Dt_Customer : Data_Cadastro  
Recency : Ult_Compra  (número de dias desde a última compra)  
MntWines : Gastos_Vinhos  (valor gasto em produtos de viniculas nos ultimos 2 anos)  
MntFruits : Gastos_Frutas  (valor gastos em frutas nos ultimos 2 anos)   
MntMeatProducts : Gastos_Carne (valor gasto em produtos de carne nos últimos 2 anos)   
MntFishProducts : Gastos_Pescados (valor gasto em produtos de pescado nos últimos 2 anos)   
MntSweetProducts : Gastos_Doces (valor gasto em produtos doces nos últimos 2 anos)   
MntGoldProds : Gastos_Ouro (valor gasto em produtos de ouro nos últimos 2 anos)   
NumDealsPurchases : Compras_com_Desconto (número de compras feito com desconto)     
NumWebPurchases :Compras_no_Site(número de compras feitas através do site da empresa)    
NumCatalogPurchases : Compras_no_Catalogo(número de compras feitas usando o catálogo)    
NumStorePurchases :Compras_na_Loja(número de compras feitas diretamente nas lojas)    
NumWebVisitsMonth :Visitas_ao_Site_Mes(número de visitas ao site da empresa no último mês)    
AcceptedCmp3 : Aceitacao_Cmp3(1 se o cliente aceitou a oferta na 3ª campanha, 0 caso contrário)    
AcceptedCmp4 : Aceitacao_Cmp4(1 se o cliente aceitou a oferta na 4ª campanha, 0 caso contrário)    
AcceptedCmp5 : Aceitacao_Cmp5(1 se o cliente aceitou a oferta na 5ª campanha, 0 caso contrário)     
AcceptedCmp1 : Aceitacao_Cmp1(1 se o cliente aceitou a oferta na 1ª campanha, 0 caso contrário)     
AcceptedCmp2 : Aceitacao_Cmp2(1 se o cliente aceitou a oferta na 2° campanha, 0 caso contrário)     
Complain : Reclamacao (1 se o cliente reclamou nos últimos 2 anos)     
Z_CostContact : Custo_Contato (tradução livre)     
Z_Revenue : Receita_Contato (tradução livre)     
Response : Resposta_Ultima_Cmp (1 se o cliente aceitou a oferta na última campanha, 0 caso contrário)
"""

# Verificação da Tradução das Colunas do DF
df.rename(columns={'Year_Birth': 'Ano_Nasc', 'Education': 'Escolaridade', 'Marital_Status': 'Estado_Civil', 'Income': 'Renda', 'Kidhome': 'Qtd_Crianca', 'Teenhome': 'Qtd_Adolescentes', 'Dt_Customer': 'Data_Cadastro', 'Recency': 'Ult_Compra', 'MntWines': 'Gastos_Vinhos', 'MntFruits': 'Gastos_Frutas', 'MntMeatProducts': 'Gastos_Carne', 'MntFishProducts': 'Gastos_Pescados', 'MntSweetProducts': 'Gastos_Doces', 'MntGoldProds': 'Gastos_Ouro', 'NumDealsPurchases': 'Compras_com_Desconto',
          'NumWebPurchases': 'Compras_no_Site', 'NumCatalogPurchases': 'Compras_no_Catalogo', 'NumStorePurchases': 'Compras_na_Loja', 'NumWebVisitsMonth': 'Visitas_ao_Site_Mes', 'AcceptedCmp3': 'Aceitacao_Cmp3', 'AcceptedCmp4': 'Aceitacao_Cmp4', 'AcceptedCmp5': 'Aceitacao_Cmp5', 'AcceptedCmp1': 'Aceitacao_Cmp1', 'AcceptedCmp2': 'Aceitacao_Cmp2', 'Complain': 'Reclamacao', 'Z_CostContact': 'Custo_Contato', 'Z_Revenue': 'Receita_Contato', 'Response': 'Resposta_Ultima_Cmp'})

# Aplicação da Tradução das Colunas
df.rename(columns={'Year_Birth': 'Ano_Nasc', 'Education': 'Escolaridade', 'Marital_Status': 'Estado_Civil', 'Income': 'Renda', 'Kidhome': 'Qtd_Crianca', 'Teenhome': 'Qtd_Adolescentes', 'Dt_Customer': 'Data_Cadastro', 'Recency': 'Ult_Compra', 'MntWines': 'Gastos_Vinhos', 'MntFruits': 'Gastos_Frutas', 'MntMeatProducts': 'Gastos_Carne', 'MntFishProducts': 'Gastos_Pescados', 'MntSweetProducts': 'Gastos_Doces', 'MntGoldProds': 'Gastos_Ouro', 'NumDealsPurchases': 'Compras_com_Desconto',
          'NumWebPurchases': 'Compras_no_Site', 'NumCatalogPurchases': 'Compras_no_Catalogo', 'NumStorePurchases': 'Compras_na_Loja', 'NumWebVisitsMonth': 'Visitas_ao_Site_Mes', 'AcceptedCmp3': 'Aceitacao_Cmp3', 'AcceptedCmp4': 'Aceitacao_Cmp4', 'AcceptedCmp5': 'Aceitacao_Cmp5', 'AcceptedCmp1': 'Aceitacao_Cmp1', 'AcceptedCmp2': 'Aceitacao_Cmp2', 'Complain': 'Reclamacao', 'Z_CostContact': 'Custo_Contato', 'Z_Revenue': 'Receita_Contato', 'Response': 'Resposta_Ultima_Cmp'}, inplace=True)

df

"""## Verificação de Valores por Coluna  
Verificação de dados pós tradução das Colunas
"""

df

"""### Colunas"""

df.info()

"""##### Constatação    
Aqui verifico que os dados númericos de fato constam como inteiros, e que apenas a coluna de Renda parece ter dados nulos

#### Coluna ID

Verifiquei os dados da coluna ID e depois sai comparando com as demais colunas, para avaliar se havia algum dado faltante.
"""

# Total de Valores da Coluna
len(df['ID'])

# Total de Valores Únicos da Coluna
df['ID'].nunique()

# Contando os Valores Nulos
df['ID'].isnull().sum()

"""##### Constatação 1  
Totas as comprar foram feitas por diferentes clientes pois o números de IDs resgistrados é igual ao número de IDs únicos.    
> Usar esse número de base para comparar com as demais colunas
"""

# Verificar Tipo dos Valores da Coluna
df['ID'].dtype

"""##### Constatação 2  
Toda a Coluna consta como tipo inteiro e não precisa de tratamento quanto a isso.   
> Verificar tipo de todas colunas e tratar incosistencas

#### Coluna Ano_Nasc
"""

# Total de Valores da Coluna
len(df['Ano_Nasc'])

# Total de Valores Únicos da Coluna
df['Ano_Nasc'].nunique()

# Contando os Valores Nulos
df['Ano_Nasc'].isnull().sum()

# Visualizando os anos de nascimento
pd.unique(df['Ano_Nasc'])

"""##### Possíveis Inconsistências    
datas: 1900,  1893, 1899   
3 pessoas com mais de 120 anos?

##### ? Questionamento    
De 2240 pessoas temos apenas 59 anos de nascimentos diferentes, qual a faixa de idade dessas pessoas? Há uma feixa específica? Se não qual faixa que usa mais o site e qual vai mais pessoalmente a loja? Se não há faixa geral em específico, qual o perfil de compra de cada faixa etárea?   
O que mais é possível se questionar com base nessa faixa de idades?

##### ? Questionamento     
Há grande diferença na faixa de idade dos cliente que não tem filhos e dos que tem crianças ou adolescentes?
"""

# Verificar Tipo dos Valores da Coluna
df['Ano_Nasc'].dtype

"""##### Constatação 2  
Toda a Coluna consta como tipo inteiro e não precisa de tratamento quanto a isso.

#### Coluna Escolaridade
"""

# Total de Valores da Coluna
len(df['Escolaridade'])

# Total de Valores Únicos da Coluna
df['Escolaridade'].nunique()

# Contando os Valores Nulos
df['Escolaridade'].isnull().sum()

"""##### ? Questionamento      
Apenas 5 níveis de escolaridade, qual o perfil de compra de cada nível de escolaridade? Qual nível de escolaridade mais compra nas lojas? Qual usa mais o site?
"""

# Visualizando os níveis de escolaridade
pd.unique(df['Escolaridade'])

"""##### * A fazer   
Traduzir valores dessa coluna

#### Coluna Estado_Civil
"""

# Total de Valores da Coluna
len(df['Estado_Civil'])

# Total de Valores Únicos da Coluna
df['Estado_Civil'].nunique()

# Contando os Valores Nulos
df['Estado_Civil'].isnull().sum()

# Visualizando os níveis de escolaridade
pd.unique(df['Estado_Civil'])

df[df['Estado_Civil'] == 'YOLO']

"""É possível que essa coluna seja cuplicada, pois todos os dados batem exatamente, exceto a aceitação da última campanha de marketing, mas por não ter certeza, não alterar

##### * A fazer   
Traduzir valores dessa coluna

##### ? Questionamento    
Qual o estado civil da maioria dos clientes? Há mudança de perfil de compra entre cliente de diferentes estados civis? Qual estado civil que mais compra?

#### Coluna Renda
"""

# Total de Valores da Coluna
len(df['Renda'])

# Total de Valores Únicos da Coluna
df['Renda'].nunique()

# Verificar Tipo dos Valores da Coluna
df['Renda'].dtype

# Visualizando todas as diferentes rendas
pd.unique(df['Renda'])

# Contando os Valores Nulos
df['Renda'].isnull().sum()

# Visualizando quais são os Valores Nulos
df[df['Renda'].isnull()]

"""##### Possíveis Inconsistências    
24 valores nulos na coluna de declração renda;   
Porém ela já consta como NaN, por isso a princípio não vi necessidade de alterar.

##### ? Questionamento    
Qual a renda média dos clientes?   
Dos clientes que mais compram, qual sua renda média?    
Dos clientes que respondem as campanhas qual renda média?

#### Coluna Qtd_Crianca
"""

# Total de Valores da Coluna
len(df['Qtd_Crianca'])

# Contando os Valores Nulos
df['Qtd_Crianca'].isnull().sum()

# Verificar Tipo dos Valores da Coluna
df['Qtd_Crianca'].dtype

# Visualizando a variação da quantidade de criança por cliente
pd.unique(df['Qtd_Crianca'])

"""##### ? Questionamento    
Clientes com 1 ou 2 crianças tem perfil de compra diferente dos que não tem?     
Estes gastam mais ou menos em determinado produto, em média, comparado aos que não tem crianças?

#### Coluna Qtd_Adolescentes
"""

# Total de Valores da Coluna
len(df['Qtd_Adolescentes'])

# Contando os Valores Nulos
df['Qtd_Adolescentes'].isnull().sum()

# Verificar Tipo dos Valores da Coluna
df['Qtd_Adolescentes'].dtype

# Visualizando a variação da quantidade de criança por cliente
pd.unique(df['Qtd_Adolescentes'])

"""##### ? Questionamento    
Clientes com 1 ou 2 adolescentes tem perfil de compra diferente dos que não tem?     
Estes gastam mais ou menos em determinado produto, em média, comparado aos que não tem crianças?

#### Coluna Data_Cadastro
"""

# Total de Valores da Coluna
len(df['Data_Cadastro'])

# Verificar Tipo dos Valores da Coluna
df['Data_Cadastro'].dtype

# Contando os Valores Nulos
df['Data_Cadastro'].isnull().sum()

"""##### ? Questionamento    
Em qual ano houve maior cadastro de cliente?    
Nesses anos há algum padrão de cadastro nos meses?(Meses que sempre tem mais cleintes cadastrados no ano e que menos tem)

##### * A fazer   
Criar coluna idade para verificar se as idades são compatíveis com a realidade, caso não quais data de nascimento estão discrepantes.

#### Coluna Ult_Compra
"""

# Total de Valores da Coluna
len(df['Ult_Compra'])

# Verificar Tipo dos Valores da Coluna
df['Ult_Compra'].dtype

# Visualizando a variação de ultima compra
pd.unique(df['Ult_Compra'])

# Contando os Valores Nulos
df['Ult_Compra'].isnull().sum()

"""##### ?  Questionamento    
Qual a frequencia média de ultima compra?    
A maioria dos cliente compram mensalmente?   
Qual a % de clientes que não recompram a certo periodo (1 a 3 meses)?

#### Coluna dos Gastos com Produtos

##### ? Questionamentos   
Qual a média de venda de cada produto?   
E anualmente? E mensalmente?   
Tem meses que certos produtos vendem mais em todos os anos?   
Qual perfil de cliente compra certos produtos acima da média de compra no geral?

#### Colunas sobre Compras

##### ? Questionamentos     

Qual quantidade de compras por cliente?   
Qual % de compras com desconto?    
As compras são feitas mais no site, catalogo ou lojas?    
Há um perfil de cliente que compra mais em algum deles?    
Qual quantidade de visitas no site, e quantas dessas converteu em vendas?    
Qual a taxa de conversão?   
Qual o perfil das pessoas que mais convertem no site?

#### Colunas Aceitação das Campanhas Mkt

##### ? Questionamentos    
Quanto cada campanha converteu?   
Qual Campanha mais converteu?   
Ela focou mais que perfil de cliente?
Qual menos converteu?   
Ela focou em qual perfil de cliente?    
A resposta na última campanha seguiu o padrão das demais campanhas?

#### Demais Colunas

##### ? Questionamentos    
Qual o total de reclamações? Qual a média de reclamação por cliente? A média de reclamação anual? E mensal? Qual ano ou mês teve mais reclamações? Tem períodos do ano que as reclamações repetem padrçoes?    
    
Qual a média de custo de contato por cliente? Qual a receita gerada em média?    
Se há variação de gasto e retorno por cliente, como isso se refletiu nas campanhas pra esse cliente?

## Confirmação e Tratamento de Inconsistências

### Observações  
- Quanto ao dados nulos da coluna de renda, eles não serão alterados no momento pois já estão num formato ideal, NaN.    
- Quanto aos anos de nascimento, será feita uma coluna idade para calcular a idade e verificar de fato quais apresentam problemas.

### Criando Coluna Idade
"""

# Verificando o tipo da coluna de ano de nascimento
df['Ano_Nasc'].dtype

# Foi usado como base o ano de 2020 a direcionamento do Professor Igor Gondim que pediu para considerar este como ano da geração dessa base de dados
df['Idade'] = 2020 - df['Ano_Nasc']

df

# Verificando as Idades
df['Idade'].unique()

"""### Conclusão do Ano de Nascimento/Idades   
De fato até idades que parecem estar inconsistêntes, as linhas que constam essas inconsistências são:
"""

df[df['Idade'] >= 120]

"""## Tradução das Linhas"""

df

"""### Tradução da Escolaridade"""

# Visualizando os níveis de escolaridade
pd.unique(df['Escolaridade'])

df.loc[df.Escolaridade == 'Graduation', ['Escolaridade']] = 'Graduação'
df.loc[df.Escolaridade == 'PhD', ['Escolaridade']] = 'Doutorado'
df.loc[df.Escolaridade == 'Master', ['Escolaridade']] = 'Mestrado'
df.loc[df.Escolaridade == 'Basic', ['Escolaridade']] = 'Ensino Fundamental'
df.loc[df.Escolaridade == '2n Cycle', ['Escolaridade']] = 'Pós Graduação'

# Visualizando os níveis de escolaridade
pd.unique(df['Escolaridade'])

"""### Tradução do Estado Civil"""

# Visualizando os estados civis
pd.unique(df['Estado_Civil'])

df.loc[df.Estado_Civil == 'Single', ['Estado_Civil']] = 'Solteiro'
df.loc[df.Estado_Civil == 'Together', ['Estado_Civil']] = 'União Estável'
df.loc[df.Estado_Civil == 'Married', ['Estado_Civil']] = 'Casado'
df.loc[df.Estado_Civil == 'Divorced', ['Estado_Civil']] = 'Divorciado'
df.loc[df.Estado_Civil == 'Widow', ['Estado_Civil']] = 'Viúvo'
df.loc[df.Estado_Civil == 'Alone', ['Estado_Civil']] = 'Alone'
df.loc[df.Estado_Civil == 'Absurd', ['Estado_Civil']] = 'Absurd'
df.loc[df.Estado_Civil == 'YOLO', ['Estado_Civil']] = 'YOLO'

# Visualizando os estados civis
pd.unique(df['Estado_Civil'])

"""##### Observação sobre Alone   
Para verificar se posso traduzir alone como sozinho, busquei saber se as pessoas que tem esse estado civil também não tem filhos ou adolescentes em casa
"""

# Criando DF só com as pessoas Alone
df_alone = df[df['Estado_Civil'] == 'Alone']

# Verificando quantas crianças e aQtd_Criancadolescentes as pessoas Alones tem
qtd_criancas = df_alone['Qtd_Crianca'].sum()
qtd_adolescentes = df_alone['Qtd_Adolescentes'].sum()

qtd_criancas

qtd_adolescentes

df_alone

"""##### Conclusão sobre Alone     
Percebi que todos os Alones tem filhos, crianças, adolescentes ou ambos. Logo conclui que a tradução aproximada seria para Pai/Mãe Solteiro, pórem por não ter certeza quanto a isso, deixei da maneira como está.

##### Demais Observações sobre a Tradução    
Yolo foi deixado como está por não achar tradução precisa para o português, siginifica you only live once, uma pessoa que é "livre" a tradução mais aproximada seria "não monogâmico" porém por não ter certeza se ela se adequava preferi não traduzir    
Absurd acreditei ser Não Informado, entendido que a pessoa que respondeu achou a pergunta absurda e respondeu dessa forma, logo não informou seu estado civil, mas por não ter certeza não traduzi.

## Schema
"""

df.dtypes

# Criando Schema pelo pandera

schema = pa.DataFrameSchema(columns={
    'Ano_Nasc': pa.Column(pa.Int),
    'Escolaridade': pa.Column(pa.String),
    'Estado_Civil': pa.Column(pa.String),
    'Renda': pa.Column(pa.Float),
    'Qtd_Crianca': pa.Column(pa.Int),
    'Qtd_Adolescentes': pa.Column(pa.Int),
    'Data_Cadastro': pa.Column(pa.DateTime),
    'Ult_Compra': pa.Column(pa.Int),
    'Gastos_Vinhos': pa.Column(pa.Int),
    'Gastos_Frutas': pa.Column(pa.Int),
    'Gastos_Carne': pa.Column(pa.Int),
    'Gastos_Pescados': pa.Column(pa.Int),
    'Gastos_Doces': pa.Column(pa.Int),
    'Gastos_Ouro': pa.Column(pa.Int),
    'Compras_com_Desconto': pa.Column(pa.Int),
    'Compras_no_Site': pa.Column(pa.Int),
    'Compras_no_Catalogo': pa.Column(pa.Int),
    'Compras_na_Loja': pa.Column(pa.Int),
    'Visitas_ao_Site_Mes': pa.Column(pa.Int),
    'Aceitacao_Cmp3': pa.Column(pa.Int),
    'Aceitacao_Cmp4': pa.Column(pa.Int),
    'Aceitacao_Cmp5': pa.Column(pa.Int),
    'Aceitacao_Cmp1': pa.Column(pa.Int),
    'Aceitacao_Cmp2': pa.Column(pa.Int),
    'Reclamacao': pa.Column(pa.Int),
    'Custo_Contato': pa.Column(pa.Int),
    'Receita_Contato': pa.Column(pa.Int),
    'Resposta_Ultima_Cmp': pa.Column(pa.Int),
    'Idade': pa.Column(pa.Int)
})

"""## Organização do Dataframe"""

df.dtypes

"""### Observação   
Novo dataframe criado, alocando as colunas do dataframe tratado, porém em ordem que julguei mais interessante, para visualizar os desvidos filtros, agrupamentos e perceber possíveis padrões.
"""

df_tratado = df[['ID', 'Data_Cadastro', 'Ano_Nasc', 'Idade', 'Escolaridade', 'Estado_Civil', 'Renda', 'Qtd_Crianca', 'Qtd_Adolescentes', 'Ult_Compra', 'Gastos_Vinhos', 'Gastos_Frutas', 'Gastos_Carne', 'Gastos_Pescados', 'Gastos_Doces', 'Gastos_Ouro',
                 'Compras_com_Desconto', 'Compras_na_Loja', 'Compras_no_Catalogo', 'Compras_no_Site', 'Visitas_ao_Site_Mes', 'Aceitacao_Cmp1', 'Aceitacao_Cmp2', 'Aceitacao_Cmp3', 'Aceitacao_Cmp4', 'Aceitacao_Cmp5', 'Resposta_Ultima_Cmp', 'Custo_Contato', 'Receita_Contato', 'Reclamacao']]

df_tratado

"""# Infra

## Load Dataframe Tratado p/ Bucket Google Cloud
"""

df_tratado.to_csv('projeto_pandasmongo_tratado.csv', index=False)

# Carregar direto no bucket
df.to_csv(
    'gs://sahtcarneirodaprojects/tratados/projeto_pandasmongo_tratado.csv', index=False)

"""## Load Dataframe Tratado p/ Database MongoDB Atlas"""

db = client['projetopandasmongo']
colecaotratados = db['tratados']
colecaotratados

dftratados_dict = df_tratado.to_dict("records")

colecaotratados.insert_many(dftratados_dict)

df_tratado.shape

colecaotratados.count_documents({})

"""# Pandas

## Filtros, Plotagens e Agrupamentos

### Perfil dos Clientes
"""

# Avaliando os valores do df mais detalhadamente
df_tratado.describe()

"""#### Conclusão da Função describe   

média de idade dos cliente = 51  
média de qnt de crianças = 0.4 (menos da metade dos clientes tem crianças)   
média qnt acolescentes = 0.5 (metade dos clientes tem acolescentes)    
ult compra = média de 49 dias desde a última compra   
média de gasto total de 605 (demonstração abaixo)   
média de 2 compras com desconto   
média de 5 compras na loja   
média de 2 compras no catalogo   
média de 4 compras no site   
média de 5 visitas ao site

#### Alteração do Dataframe   
Para melhor visualizar o gasto médio total dos cliente será necessário criar outra coluna contendo a média dos valores das diferentes colunas de gastos.
"""

# Defini que a soma das colunas de gastos com produtos é igual ao gasto total
gasto_total = df_tratado[['Gastos_Vinhos', 'Gastos_Frutas', 'Gastos_Carne',
                          'Gastos_Pescados', 'Gastos_Doces', 'Gastos_Ouro']].sum(axis=1)

# Criei uma nova coluna gasto total e aloquei o valor do gasto total por cliente nela
df_tratado['Gasto_Total'] = gasto_total

# Avaliando a média de gasto total
df_tratado[['Gasto_Total']].mean()

"""#### Novos Dfs para demonstração"""

# Criando novo df apenas com os dados relacionados a gastos dos clientes
df_media_gastos = df_tratado[['Gasto_Total', 'Gastos_Vinhos', 'Gastos_Frutas',
                              'Gastos_Carne', 'Gastos_Pescados', 'Gastos_Doces', 'Gastos_Ouro']]

df_media_gastos.head(5)

"""#### Gastos Médios"""

# Tirando a média de gastos por produtos e total
df_media_gastos.mean()

# Mostrando a diferença de média de gastos por produtos e total
df_media_gastos.mean().plot.bar(figsize=(24, 8))

# Alocando apenas as colunas de gastos com produtos, tirando a média e apresentando graficamente
df_media_gastos_produtos = df_media_gastos[[
    'Gastos_Vinhos', 'Gastos_Frutas', 'Gastos_Carne', 'Gastos_Pescados', 'Gastos_Doces', 'Gastos_Ouro']]
df_media_gastos_produtos.mean().plot.pie(figsize=(24, 8))

"""##### Constatações   
O gasto médio com vinhos se aproxima do gasto médio total;   
O segundo produto com maior gasto médio é a carne, e tem pouco mais da metade do gasto médio com vinhos;  
O produto com menor gasto média são as frutas.

#### Gasto total por Idade
"""

# Grafico barra de gasto total por idade
df_tratado.plot.bar(x="Idade", y="Gasto_Total", figsize=(24, 8))

# Grafico de disperção do gasto total por idade
df_tratado.plot.scatter(x="Idade", y="Gasto_Total", figsize=(24, 8))

"""##### Constatação  
Não há um desvio padrão que ligue a idade do cliente diretamente ao seu gasto total na loja.

#### Renda média por Escolaridade
"""

# Criando novo df apenas com os dados de renda e escolaridade para facilitar manipulação
df_renda_escolaridade = df_tratado[['Renda', 'Escolaridade']]

# Criando agrupamento, dropando as linhas onde a Renda consta como NaN, e tirando as médias da Renda por escolaridade
renda_media_escolaridade = df_renda_escolaridade.dropna(
    subset=['Renda']).groupby('Escolaridade').mean()

# Análise númerica do resultado disso
renda_media_escolaridade

# Análise gráfica do resultado
renda_media_escolaridade.plot.bar(figsize=(24, 8))

"""#### Proporção de Clientes com ensino superior e sem ensino superior"""

# Criando df para diferenciar os cliente formados no ensino superior e os não formados
df_formacao = df_renda_escolaridade[['Escolaridade']]
df_formacao.loc[df_formacao['Escolaridade'] ==
                'Doutorado', 'Formacao'] = "Ensino Superior"
df_formacao.loc[df_formacao['Escolaridade'] ==
                'Mestrado', 'Formacao'] = "Ensino Superior"
df_formacao.loc[df_formacao['Escolaridade'] ==
                'Graduação', 'Formacao'] = "Ensino Superior"
df_formacao.loc[df_formacao['Escolaridade'] ==
                'Pós Graduação', 'Formacao'] = "Ensino Superior"
df_formacao.loc[df_formacao['Escolaridade'] ==
                'Ensino Fundamental', 'Formacao'] = "Ensino Fundamental"

# Agrupando os clientes por tipo de formação (Superior ou Fundamental) numericamente

df_formacao.groupby('Formacao').count()

# Agrupando os clientes por tipo de formação (Superior ou Fundamental) graficamente
df_formacao.groupby('Formacao').size().sort_values(
    ascending=False).plot.pie(figsize=(24, 8))

"""##### Constatação
As pessoas com doutora tem a renda maior, em média 56.145    
Já as pessoas com apenas ensino fundamental tem a renda menor, em média 20.306
As pessoas com apenas ensino fundamental ganham menos metade das pessoas formadas.  
Já entre os demais níveis de escolaridade, em média, a diferença de renda é inferior a 10 mil.   
Temos 2186 cliente formados no ensino superior e apenas 54 formados apenas no ensino fundamental.

#### Gasto Total por Renda
"""

# Criando novo dataframe apenas com os dados a serem usados nessa análise
df_gasto_renda = df_tratado[['Renda', 'Gasto_Total']]

df_gasto_renda.groupby('Renda').sum().plot.bar(figsize=(24, 8))

"""O gráfico de gasto por renda ficou muito disperço e muito amplo, mas já é possível ver que há uma ligação de quanto a pessoa tem de renda com o quanto ela gasta na loja, então decidi dividir o publico em faixas de renda para visualizar melhor"""

# Criando nova coluna de Faixa Salarial e Separando as Pessoas com Base na sua faixa de renda
df_gasto_renda.loc[df_gasto_renda['Renda']
                   <= 10000, 'Faixa_Salarial'] = 'Ate10.000'
df_gasto_renda.loc[(df_gasto_renda['Renda'] > 10000) & (
    df_gasto_renda['Renda'] <= 20000), 'Faixa_Salarial'] = 'Ate20.000'
df_gasto_renda.loc[(df_gasto_renda['Renda'] > 20000) & (
    df_gasto_renda['Renda'] <= 30000), 'Faixa_Salarial'] = 'Ate30.000'
df_gasto_renda.loc[(df_gasto_renda['Renda'] > 30000) & (
    df_gasto_renda['Renda'] <= 40000), 'Faixa_Salarial'] = 'Ate40.000'
df_gasto_renda.loc[(df_gasto_renda['Renda'] > 40000) & (
    df_gasto_renda['Renda'] <= 50000), 'Faixa_Salarial'] = 'Ate50.000'
df_gasto_renda.loc[df_gasto_renda['Renda'] >
                   50000, 'Faixa_Salarial'] = 'Mais50.000'

# Quantas pessoas estão em cada faixa salárial
df_gasto_renda['Faixa_Salarial'].value_counts()

# Agrumando as pessoas pela faixa salarial por renda
df_gasto_renda.groupby('Faixa_Salarial')[
    'Gasto_Total'].sum().plot.bar(figsize=(24, 8))

# Agrupando os clientes por sua faixa de renda
df_gasto_renda.groupby('Faixa_Salarial')['Gasto_Total'].sum(
).sort_values(ascending=False).plot.pie(figsize=(24, 8))

"""##### Constatação  
Aqui fica claro que as pessoas com maiores rendas tem um gasto toral maior.   
Fica evidente a ligação da renda média com o gasto total.   
Temos 1156 que tem renda maior de 50 mil  
328 que tem renda entre 40 e 50 mil   
362 que tem renda entre 30 e 40 mil   
243 que tem renda entre 20 e 30 mil   
98 que tem renda entre 10 e 20 mil   
e 29 que tem renda de 10 mil ou inferior

#### Propoção de Clientes com e sem filhos
"""

# Criando novo df para alocar apenas quantidade de filhos do cliente e qual é o cliente(ID)
df_total_filho = df_tratado[['ID', 'Qtd_Crianca', 'Qtd_Adolescentes']]

# Formando nova coluna que soma os valores de crianças e adolescentes
df_total_filho['Tem_Filho'] = df_total_filho['Qtd_Crianca'] + \
    df_total_filho['Qtd_Adolescentes']

# Novo df que pega apenas as informações da nova coluna
df_filhos = df_total_filho[["Tem_Filho"]]

df_filhos

# Transformando o valor dos filhos em informação do Tipo SIM ou NAO, para verifficar apenas se ele tem ou não filhos
df_filhos.loc[df_filhos['Tem_Filho'] >= 1, 'Tem_Filho'] = 'SIM'

df_filhos.loc[df_filhos['Tem_Filho'] == 0, 'Tem_Filho'] = 'NAO'

# Contando quantos clientes tem filhos e quantos não tem filhos
df_filhos.value_counts()

# Agrupando os clientes que tem e não tem filhos
df_filhos.groupby('Tem_Filho').size().sort_values(
    ascending=False).plot.pie(x='Tem_filhos', figsize=(24, 8))

"""##### Constatação   
A maioria dos clientes tem filhos, sendo eles 1602, contra apenas 638 que não tem filhos.

### Campanhas de Marketing
"""

# Criando novo df que pega apenas as informações ligadas as campanhas de marketing
df_campanhas = df_tratado[['Aceitacao_Cmp1', 'Aceitacao_Cmp2', 'Aceitacao_Cmp3',
                           'Aceitacao_Cmp4', 'Aceitacao_Cmp5', 'Resposta_Ultima_Cmp', 'Custo_Contato', 'Receita_Contato']]

df_tratado.head(3)

df_campanhas.head(3)

# Separando eem df a informação de cada campanhas e das campanhas de maneira geral, apara manipular individualmente
df_aceitacao_campanhas = df_campanhas[['Aceitacao_Cmp1', 'Aceitacao_Cmp2',
                                       'Aceitacao_Cmp3', 'Aceitacao_Cmp4', 'Aceitacao_Cmp5', 'Resposta_Ultima_Cmp']]
df_aceitacao_campanha1 = df_campanhas[['Aceitacao_Cmp1']]
df_aceitacao_campanha2 = df_campanhas[['Aceitacao_Cmp2']]
df_aceitacao_campanha3 = df_campanhas[['Aceitacao_Cmp3']]
df_aceitacao_campanha4 = df_campanhas[['Aceitacao_Cmp4']]
df_aceitacao_campanha5 = df_campanhas[['Aceitacao_Cmp5']]
df_aceitacao_ultcampanha = df_campanhas[['Resposta_Ultima_Cmp']]

# Nos df das campanhas individuais trocando os valores de 1 para SIM e 0 para NAO
df_aceitacao_campanha1.loc[df_aceitacao_campanha1['Aceitacao_Cmp1']
                           == 1, 'Aceitacao_Cmp1'] = "SIM"
df_aceitacao_campanha1.loc[df_aceitacao_campanha1['Aceitacao_Cmp1']
                           == 0, 'Aceitacao_Cmp1'] = "NAO"

df_aceitacao_campanha2.loc[df_aceitacao_campanha2['Aceitacao_Cmp2']
                           == 1, 'Aceitacao_Cmp2'] = "SIM"
df_aceitacao_campanha2.loc[df_aceitacao_campanha2['Aceitacao_Cmp2']
                           == 0, 'Aceitacao_Cmp2'] = "NAO"

df_aceitacao_campanha3.loc[df_aceitacao_campanha3['Aceitacao_Cmp3']
                           == 1, 'Aceitacao_Cmp3'] = "SIM"
df_aceitacao_campanha3.loc[df_aceitacao_campanha3['Aceitacao_Cmp3']
                           == 0, 'Aceitacao_Cmp3'] = "NAO"

df_aceitacao_campanha4.loc[df_aceitacao_campanha4['Aceitacao_Cmp4']
                           == 1, 'Aceitacao_Cmp4'] = "SIM"
df_aceitacao_campanha4.loc[df_aceitacao_campanha4['Aceitacao_Cmp4']
                           == 0, 'Aceitacao_Cmp4'] = "NAO"

df_aceitacao_campanha5.loc[df_aceitacao_campanha5['Aceitacao_Cmp5']
                           == 1, 'Aceitacao_Cmp5'] = "SIM"
df_aceitacao_campanha5.loc[df_aceitacao_campanha5['Aceitacao_Cmp5']
                           == 0, 'Aceitacao_Cmp5'] = "NAO"

df_aceitacao_ultcampanha.loc[df_aceitacao_ultcampanha['Resposta_Ultima_Cmp']
                             == 1, 'Resposta_Ultima_Cmp'] = "SIM"
df_aceitacao_ultcampanha.loc[df_aceitacao_ultcampanha['Resposta_Ultima_Cmp']
                             == 0, 'Resposta_Ultima_Cmp'] = "NAO"

"""#### Visão geral da aceitação das campanhas"""

# Demonstração númerica de quantos clientes aceitaram a campanha
# Aqui foi possível apenas somar pois usei o df com apenas 1 e 0, então somaria apenas as respostas positivas
df_aceitacao_campanhas.sum()

# Demonstração grafica da soma anterior
df_aceitacao_campanhas.sum().plot.bar(figsize=(24, 8))

"""#### Aceitação da 1° Campanha"""

# Conta da quantidade de valores de SIM e NAO desta campanha
df_aceitacao_campanha1['Aceitacao_Cmp1'].value_counts()

# Considerando o total de 2240 clientes, avliando qual a % de conversão essa campanha gerou
clientes_convertidos = 144
total_clientes = 2240
porcentagem_conversao = (clientes_convertidos / total_clientes) * 100
print(f'A conversão dessa campanha foi de {porcentagem_conversao}%')

# Demonstração grafica do que foi apresentado anteriormente por agrupamento e plotagem
df_aceitacao_campanha1.groupby('Aceitacao_Cmp1').size(
).sort_values(ascending=False).plot.pie(figsize=(24, 8))

"""#### Aceitação da 2° Campanha"""

# Conta da quantidade de valores de SIM e NAO desta campanha
df_aceitacao_campanha2['Aceitacao_Cmp2'].value_counts()

# Considerando o total de 2240 clientes, avliando qual a % de conversão essa campanha gerou
clientes_convertidos = 30
total_clientes = 2240
porcentagem_conversao = (clientes_convertidos / total_clientes) * 100
print(f'A conversão dessa campanha foi de {porcentagem_conversao}%')

# Demonstração grafica do que foi apresentado anteriormente por agrupamento e plotagem
df_aceitacao_campanha2.groupby('Aceitacao_Cmp2').size(
).sort_values(ascending=False).plot.pie(figsize=(24, 8))

"""#### Aceitação da 3° Campanha"""

# Conta da quantidade de valores de SIM e NAO desta campanha
df_aceitacao_campanha3['Aceitacao_Cmp3'].value_counts()

# Considerando o total de 2240 clientes, avliando qual a % de conversão essa campanha gerou
clientes_convertidos = 163
total_clientes = 2240
porcentagem_conversao = (clientes_convertidos / total_clientes) * 100
print(f'A conversão dessa campanha foi de {porcentagem_conversao}%')

# Demonstração grafica do que foi apresentado anteriormente por agrupamento e plotagem
df_aceitacao_campanha3.groupby('Aceitacao_Cmp3').size(
).sort_values(ascending=False).plot.pie(figsize=(24, 8))

"""#### Aceitação da 4° Campanha"""

# Conta da quantidade de valores de SIM e NAO desta campanha
df_aceitacao_campanha4['Aceitacao_Cmp4'].value_counts()

# Considerando o total de 2240 clientes, avliando qual a % de conversão essa campanha gerou
clientes_convertidos = 167
total_clientes = 2240
porcentagem_conversao = (clientes_convertidos / total_clientes) * 100
print(f'A conversão dessa campanha foi de {porcentagem_conversao}%')

# Demonstração grafica do que foi apresentado anteriormente por agrupamento e plotagem
df_aceitacao_campanha4.groupby('Aceitacao_Cmp4').size(
).sort_values(ascending=False).plot.pie(figsize=(24, 8))

"""#### Aceitação 5° Campanha"""

# Conta da quantidade de valores de SIM e NAO desta campanha
df_aceitacao_campanha5['Aceitacao_Cmp5'].value_counts()

# Considerando o total de 2240 clientes, avliando qual a % de conversão essa campanha gerou
clientes_convertidos = 163
total_clientes = 2240
porcentagem_conversao = (clientes_convertidos / total_clientes) * 100
print(f'A conversão dessa campanha foi de {porcentagem_conversao}%')

# Demonstração grafica do que foi apresentado anteriormente por agrupamento e plotagem
df_aceitacao_campanha5.groupby('Aceitacao_Cmp5').size(
).sort_values(ascending=False).plot.pie(figsize=(24, 8))

"""#### Última Campanha"""

# Conta da quantidade de valores de SIM e NAO desta campanha
df_aceitacao_ultcampanha['Resposta_Ultima_Cmp'].value_counts()

# Considerando o total de 2240 clientes, avliando qual a % de conversão essa campanha gerou
clientes_convertidos = 334
total_clientes = 2240
porcentagem_conversao = (clientes_convertidos / total_clientes) * 100
print(f'A conversão dessa campanha foi de {porcentagem_conversao}%')

# Demonstração grafica do que foi apresentado anteriormente por agrupamento e plotagem
df_aceitacao_ultcampanha.groupby('Resposta_Ultima_Cmp').size(
).sort_values(ascending=False).plot.pie(figsize=(24, 8))

"""#### Constatações sobre as Campanhas de MArketing

Aceitacao_Cmp1    144 / Aceitacao_Cmp2     30 / Aceitacao_Cmp3    163 / Aceitacao_Cmp4    167 / Aceitacao_Cmp5    163    
    
Com esses dados é possível perceber que a segunda campanhas de marketing foi a que menos converteu clientes.   
Porém todas as campanhas tiveram baixa conversão:   
   
Campanha 1:   
NAO    2096 / SIM     144    
Conversão de: 6.4%   
   
Campanha 2:   
NAO    2210 / SIM      30   
Conversão de: 1.3%   
   
Campanha 3:   
NAO    2077 / SIM     163   
Conversão de: 7.2%   
   
Campanha 4:   
NAO    2073 / SIM     167   
Conversão de: 7.4%   
   
Campanha 5:    
NAO    2077 / SIM     163   
Conversão de: 7.2%

Ult Campanha:   
NAO 1906 / SIM 334    
Conversão de: 14.9%

# Conclusão Final/Sugestão

## Conclusão Perfil de Cliente

O cliente médio da loja tem em torno de 51 anos, é formado no ensino superior, tem renda média de mais de 50mil, é provável que tenha ao menos 1 filho e gasta mais com vinhos e carne.

Essa conclusão é embasada nos seguintes dados:
"""

# Idade média dos clientes
df_tratado['Idade'].mean()

# Grau de Escolaridade dos Clientes de maneira bivalente (entre ensino superior e fundamental)
df_formacao.groupby('Formacao').size().sort_values(
    ascending=False).plot.pie(figsize=(24, 8))

# Faixa de renda média dos clientes
df_gasto_renda.groupby('Faixa_Salarial')[
    'Gasto_Total'].sum().plot.bar(figsize=(24, 8))

# Clientes tem filho?
df_filhos.groupby('Tem_Filho').size().sort_values(
    ascending=False).plot.pie(x='Tem_filhos', figsize=(24, 8))

# Gasto médio dos clientes por produto
df_media_gastos_produtos.mean().plot.pie(figsize=(24, 8))

"""## Conclusão das Campanhas de Marketing

A campanha de marketing que teve maior retorno foi a ultima campanha, com uma taxa de conversão quase 15%, e a que teve menor retorno foi a 2° campanha, com uma taxa de conversão de apenas 1.3%.   
As campanhas 3, 4 e 5 tiveram taxas de conversão muito próximas.

Essa conclusão é embasada nos seguintes dados:
"""

# Quantidade de pessoas que aceitou cada campanha de marketing
df_aceitacao_campanhas.sum()

# Agrupamento mostrando de maneira grafica conversão de cada campanha
df_aceitacao_campanhas.sum().plot.bar(figsize=(24, 8))

"""## Sugestões

- É preciso avaliar o que ocorreu na segunda campanha de marketing para haver uma queda tão brusca de conversão comparada as demais campanhas.  
- Além disso é preciso avaliar o motivo das taxas de conversões serem todas abaixo de 10%.
- É preciso focar nos clientes que mais compram na loja, sendo eles pessoas de 51 anos, que tem renda média de mais de 50mil e são formados no ensino superior.
- É preciso equilibrar os produtos, dando maior enfâse aos produtos mais buscados na loja, sendo eles vinhos e carnes(mais de 80% das vendas), e menor enfâse ao menos buscado, sendo eles as frutas.
"""
